training:
  num_epochs: 1
  batch_size: 8
  checkpoint_interval: 10
  seed: 42
data:
  sample_size: 100
  test_size: 0.1
model:
  pretrained_name: "bert-base-uncased"
  num_labels: 2
  dropout_rate: 0.1
  gradient_checkpointing: false
optimizer:
  type: "adamw"
  learning_rate: 2.0e-5
  weight_decay: 0.01
  scheduler: "linear"
  warmup_ratio: 0.1
